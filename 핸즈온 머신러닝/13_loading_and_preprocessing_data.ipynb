{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "13_loading_and_preprocessing_data",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6iPc15I-BJS"
      },
      "source": [
        "# Cahpter13 텐서플로에서 데이터 적재와 전처리하기"
      ]
    }, 
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZZQjhFDEmdg"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRW7CdbSNJcM",
        "outputId": "b24cc2b1-bfee-427c-b125-5f11dc170f38"
      },
      "source": [
        "# 파이썬 ≥3.5 필수\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# 사이킷런 ≥0.20 필수\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "try:\n",
        "    # %tensorflow_version은 코랩 명령입니다.\n",
        "    %tensorflow_version 2.x\n",
        "    !pip install -q -U tfx\n",
        "    print(\"패키지 호환 에러는 무시해도 괜찮습니다.\")\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# 텐서플로 ≥2.0 필수\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "# 공통 모듈 임포트\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# 노트북 실행 결과를 동일하게 유지하기 위해\n",
        "np.random.seed(42)\n",
        "\n",
        "# 깔끔한 그래프 출력을 위해\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# 그림을 저장할 위치\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"data\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"그림 저장:\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.4 MB 5.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 147 kB 59.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 19.0 MB 1.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 87.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 75.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 50.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 55.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 454.4 MB 10.0 kB/s \n",
            "\u001b[K     |████████████████████████████████| 17.7 MB 79 kB/s \n",
            "\u001b[K     |████████████████████████████████| 135 kB 61.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 52.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 75.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 9.8 MB 43.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 406 kB 80.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 189 kB 76.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 40 kB 7.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 49 kB 6.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 62 kB 985 kB/s \n",
            "\u001b[K     |████████████████████████████████| 151 kB 68.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 829 kB 62.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 249 kB 42.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 58.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 183 kB 91.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 83 kB 2.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 267 kB 69.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 435 kB 85.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 77.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 180 kB 65.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 169 kB 67.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 255 kB 80.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 173 kB 83.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 105 kB 54.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 188 kB 60.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 188 kB 64.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 75 kB 4.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 105 kB 62.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 105 kB 73.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 105 kB 66.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 105 kB 52.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 77.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 462 kB 72.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 35.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 294 kB 76.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 788 kB 86.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 370 kB 55.2 MB/s \n",
            "\u001b[?25h  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for google-apitools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for grpc-google-iam-v1 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pandas-gbq 0.13.3 requires google-cloud-bigquery[bqstorage,pandas]<2.0.0dev,>=1.11.1, but you have google-cloud-bigquery 2.18.0 which is incompatible.\n",
            "multiprocess 0.70.12.2 requires dill>=0.3.4, but you have dill 0.3.1.1 which is incompatible.\n",
            "jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.20 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.28.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "패키지 호환 에러는 무시해도 괜찮습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f50I5Gc7-F9t"
      },
      "source": [
        "### 13.1 데이터 API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wO5CRXVABjJR"
      },
      "source": [
        "메모리 용량에 맞지 않는 아주 큰 규모의 데이터셋으로 딥러닝 시스템을 훈련해야 하는 경우에 **데이터 API**로 이를 쉽게 처리할 수 있다.\n",
        "\n",
        "- 데이터셋 : \n",
        " \n",
        " 연속된 데이터 샘플\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZAyxXD9Vbeq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3aa8a4bf-e638-4f50-87db-164c021ecffb"
      },
      "source": [
        "# 메모리에서 전체 데이터셋 생성\n",
        "X = tf.range(10)   # 샘플 데이터 텐서\n",
        "dataset = tf.data.Dataset.from_tensor_slices(X)\n",
        "dataset"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: (), types: tf.int32>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpUDatE7M9Co",
        "outputId": "534b9246-e151-43ad-e57b-af7ff91a426a"
      },
      "source": [
        "for item in dataset:\n",
        "    print(item)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(0, shape=(), dtype=int32)\n",
            "tf.Tensor(1, shape=(), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n",
            "tf.Tensor(3, shape=(), dtype=int32)\n",
            "tf.Tensor(4, shape=(), dtype=int32)\n",
            "tf.Tensor(5, shape=(), dtype=int32)\n",
            "tf.Tensor(6, shape=(), dtype=int32)\n",
            "tf.Tensor(7, shape=(), dtype=int32)\n",
            "tf.Tensor(8, shape=(), dtype=int32)\n",
            "tf.Tensor(9, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gC7fDHA__rOD"
      },
      "source": [
        "- 연쇄 변환"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TV_iCNLNC1v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2850d63c-f2cc-4156-bae0-7dd020136998"
      },
      "source": [
        "dataset = dataset.repeat(3).batch(7)  # 3에포크, 배치크기:7\n",
        "for item in dataset:\n",
        "    print(item)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int32)\n",
            "tf.Tensor([7 8 9 0 1 2 3], shape=(7,), dtype=int32)\n",
            "tf.Tensor([4 5 6 7 8 9 0], shape=(7,), dtype=int32)\n",
            "tf.Tensor([1 2 3 4 5 6 7], shape=(7,), dtype=int32)\n",
            "tf.Tensor([8 9], shape=(2,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsxrRj6f9Mwj"
      },
      "source": [
        "# map()메서드로 각 아이템 변환\n",
        "dataset = dataset.map(lambda x: x * 2)  # 아이템: [0,2,4,6,8,10,12]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdJ-vW2D-NWg",
        "outputId": "e71605b2-f9fe-401b-9a37-dd0b0f3b70f1"
      },
      "source": [
        "for item in dataset:\n",
        "    print(item)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([ 0  2  4  6  8 10 12], shape=(7,), dtype=int32)\n",
            "tf.Tensor([14 16 18  0  2  4  6], shape=(7,), dtype=int32)\n",
            "tf.Tensor([ 8 10 12 14 16 18  0], shape=(7,), dtype=int32)\n",
            "tf.Tensor([ 2  4  6  8 10 12 14], shape=(7,), dtype=int32)\n",
            "tf.Tensor([16 18], shape=(2,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSx4xijD-eCc",
        "outputId": "b744f998-3002-4825-ce70-0183dfbe34ae"
      },
      "source": [
        "# apply(): 데이터셋 전체에 변환 적용\n",
        "dataset = dataset.apply(tf.data.experimental.unbatch())\n",
        "for item in dataset:\n",
        "    print(item)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(0, shape=(), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n",
            "tf.Tensor(4, shape=(), dtype=int32)\n",
            "tf.Tensor(6, shape=(), dtype=int32)\n",
            "tf.Tensor(8, shape=(), dtype=int32)\n",
            "tf.Tensor(10, shape=(), dtype=int32)\n",
            "tf.Tensor(12, shape=(), dtype=int32)\n",
            "tf.Tensor(14, shape=(), dtype=int32)\n",
            "tf.Tensor(16, shape=(), dtype=int32)\n",
            "tf.Tensor(18, shape=(), dtype=int32)\n",
            "tf.Tensor(0, shape=(), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n",
            "tf.Tensor(4, shape=(), dtype=int32)\n",
            "tf.Tensor(6, shape=(), dtype=int32)\n",
            "tf.Tensor(8, shape=(), dtype=int32)\n",
            "tf.Tensor(10, shape=(), dtype=int32)\n",
            "tf.Tensor(12, shape=(), dtype=int32)\n",
            "tf.Tensor(14, shape=(), dtype=int32)\n",
            "tf.Tensor(16, shape=(), dtype=int32)\n",
            "tf.Tensor(18, shape=(), dtype=int32)\n",
            "tf.Tensor(0, shape=(), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n",
            "tf.Tensor(4, shape=(), dtype=int32)\n",
            "tf.Tensor(6, shape=(), dtype=int32)\n",
            "tf.Tensor(8, shape=(), dtype=int32)\n",
            "tf.Tensor(10, shape=(), dtype=int32)\n",
            "tf.Tensor(12, shape=(), dtype=int32)\n",
            "tf.Tensor(14, shape=(), dtype=int32)\n",
            "tf.Tensor(16, shape=(), dtype=int32)\n",
            "tf.Tensor(18, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTxReM1v-tT4",
        "outputId": "26665cf8-bca8-424f-d871-3dcea24af818"
      },
      "source": [
        "# filter()로 데이터셋 필터링\n",
        "dataset = dataset.filter(lambda x: x < 10)\n",
        "for item in dataset:\n",
        "    print(item)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(0, shape=(), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n",
            "tf.Tensor(4, shape=(), dtype=int32)\n",
            "tf.Tensor(6, shape=(), dtype=int32)\n",
            "tf.Tensor(8, shape=(), dtype=int32)\n",
            "tf.Tensor(0, shape=(), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n",
            "tf.Tensor(4, shape=(), dtype=int32)\n",
            "tf.Tensor(6, shape=(), dtype=int32)\n",
            "tf.Tensor(8, shape=(), dtype=int32)\n",
            "tf.Tensor(0, shape=(), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n",
            "tf.Tensor(4, shape=(), dtype=int32)\n",
            "tf.Tensor(6, shape=(), dtype=int32)\n",
            "tf.Tensor(8, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1cldvDn_JnX",
        "outputId": "ed5728da-272c-4ece-aef4-eb8cb7735b6e"
      },
      "source": [
        "for item in dataset.take(3):   # take(n): n개의 아이템만 보고 싶을 때 사용\n",
        "    print(item)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(0, shape=(), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n",
            "tf.Tensor(4, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FHoQlKD_tHK"
      },
      "source": [
        "- 데이터 셔플링\n",
        "\n",
        " shuffle()메서드를 사용하여 샘플을 섞는다 --> 버퍼 크기를 지정해주어야 한다.\n",
        "\n",
        " 버퍼 크기는 충분히 크게 하는 것이 중요하지만 보유한 메모리 크기를 넘지 않아야 하며, 데이터셋 크기보다 클 필요는 없다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGoE3mLu_RGX",
        "outputId": "e41b70fd-096d-47a3-fce9-e27a93a906b2"
      },
      "source": [
        "dataset = tf.data.Dataset.range(10).repeat(3)  # 0 ~ 9까지 세 번 반복\n",
        "dataset = dataset.shuffle(buffer_size=5, seed=42).batch(7)\n",
        "for item in dataset:\n",
        "    print(item)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([0 2 3 6 7 9 4], shape=(7,), dtype=int64)\n",
            "tf.Tensor([5 0 1 1 8 6 5], shape=(7,), dtype=int64)\n",
            "tf.Tensor([4 8 7 1 2 3 0], shape=(7,), dtype=int64)\n",
            "tf.Tensor([5 4 2 7 8 9 9], shape=(7,), dtype=int64)\n",
            "tf.Tensor([3 6], shape=(2,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZNO3yfWDYDN"
      },
      "source": [
        "샘플을 더 섞기 위해 원본 데이터를 여러 파일로 나눈 다음 훈련하는 동안 무작위로 읽기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYstoYKbBbEu",
        "outputId": "9e941bdd-dbe1-47ea-9ecf-f6325d7ce26b"
      },
      "source": [
        "# 캘리포니아 주택 데이터셋 적재\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
        "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X_train_full, y_train_full, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_mean = scaler.mean_\n",
        "X_std = scaler.scale_"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to /root/scikit_learn_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qh8U7lW0EHxx"
      },
      "source": [
        "메모리에 맞지 않는 매우 큰 데이터셋인 경우 일반적으로 먼저 여러 개의 파일로 나누고 텐서플로에서 이 파일들을 병렬로 읽게한다.\n",
        "\n",
        "데모를 위해 주택 데이터셋을 20개의 CSV 파일로 나누어 보자"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwokgIkVDrn7"
      },
      "source": [
        "def save_to_multiple_csv_files(data, name_prefix, header=None, n_parts=10):\n",
        "    housing_dir = os.path.join(\"datasets\", \"housing\")\n",
        "    os.makedirs(housing_dir, exist_ok=True)\n",
        "    path_format = os.path.join(housing_dir, \"my_{}_{:02d}.csv\")\n",
        "\n",
        "    filepaths = []\n",
        "    m = len(data)\n",
        "    for file_idx, row_indices in enumerate(np.array_split(np.arange(m), n_parts)):\n",
        "        part_csv = path_format.format(name_prefix, file_idx)\n",
        "        filepaths.append(part_csv)\n",
        "        with open(part_csv, \"wt\", encoding=\"utf-8\") as f:\n",
        "            if header is not None:\n",
        "                f.write(header)\n",
        "                f.write(\"\\n\")\n",
        "            for row_idx in row_indices:\n",
        "                f.write(\",\".join([repr(col) for col in data[row_idx]]))\n",
        "                f.write(\"\\n\")\n",
        "    return filepaths"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaRd1xovEGba"
      },
      "source": [
        "train_data = np.c_[X_train, y_train]\n",
        "valid_data = np.c_[X_valid, y_valid]\n",
        "test_data = np.c_[X_test, y_test]\n",
        "header_cols = housing.feature_names + [\"MedianHouseValue\"]\n",
        "header = \",\".join(header_cols)\n",
        "\n",
        "train_filepaths = save_to_multiple_csv_files(train_data, \"train\", header, n_parts=20)\n",
        "valid_filepaths = save_to_multiple_csv_files(valid_data, \"valid\", header, n_parts=10)\n",
        "test_filepaths = save_to_multiple_csv_files(test_data, \"test\", header, n_parts=10)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mX3bFQHsEVZg",
        "outputId": "52b24273-57b9-4741-8413-51845c40a87a"
      },
      "source": [
        "train_filepaths  # 20개의 파일로 나누어짐"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['datasets/housing/my_train_00.csv',\n",
              " 'datasets/housing/my_train_01.csv',\n",
              " 'datasets/housing/my_train_02.csv',\n",
              " 'datasets/housing/my_train_03.csv',\n",
              " 'datasets/housing/my_train_04.csv',\n",
              " 'datasets/housing/my_train_05.csv',\n",
              " 'datasets/housing/my_train_06.csv',\n",
              " 'datasets/housing/my_train_07.csv',\n",
              " 'datasets/housing/my_train_08.csv',\n",
              " 'datasets/housing/my_train_09.csv',\n",
              " 'datasets/housing/my_train_10.csv',\n",
              " 'datasets/housing/my_train_11.csv',\n",
              " 'datasets/housing/my_train_12.csv',\n",
              " 'datasets/housing/my_train_13.csv',\n",
              " 'datasets/housing/my_train_14.csv',\n",
              " 'datasets/housing/my_train_15.csv',\n",
              " 'datasets/housing/my_train_16.csv',\n",
              " 'datasets/housing/my_train_17.csv',\n",
              " 'datasets/housing/my_train_18.csv',\n",
              " 'datasets/housing/my_train_19.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "WcbHGdJ3EcmU",
        "outputId": "e71c5a66-735f-418c-99c5-4ac21fd43dbb"
      },
      "source": [
        "pd.read_csv(train_filepaths[0]).head()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MedInc</th>\n",
              "      <th>HouseAge</th>\n",
              "      <th>AveRooms</th>\n",
              "      <th>AveBedrms</th>\n",
              "      <th>Population</th>\n",
              "      <th>AveOccup</th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "      <th>MedianHouseValue</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.5214</td>\n",
              "      <td>15.0</td>\n",
              "      <td>3.049945</td>\n",
              "      <td>1.106548</td>\n",
              "      <td>1447.0</td>\n",
              "      <td>1.605993</td>\n",
              "      <td>37.63</td>\n",
              "      <td>-122.43</td>\n",
              "      <td>1.442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.3275</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.490060</td>\n",
              "      <td>0.991054</td>\n",
              "      <td>3464.0</td>\n",
              "      <td>3.443340</td>\n",
              "      <td>33.69</td>\n",
              "      <td>-117.39</td>\n",
              "      <td>1.687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.1000</td>\n",
              "      <td>29.0</td>\n",
              "      <td>7.542373</td>\n",
              "      <td>1.591525</td>\n",
              "      <td>1328.0</td>\n",
              "      <td>2.250847</td>\n",
              "      <td>38.44</td>\n",
              "      <td>-122.98</td>\n",
              "      <td>1.621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7.1736</td>\n",
              "      <td>12.0</td>\n",
              "      <td>6.289003</td>\n",
              "      <td>0.997442</td>\n",
              "      <td>1054.0</td>\n",
              "      <td>2.695652</td>\n",
              "      <td>33.55</td>\n",
              "      <td>-117.70</td>\n",
              "      <td>2.621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0549</td>\n",
              "      <td>13.0</td>\n",
              "      <td>5.312457</td>\n",
              "      <td>1.085092</td>\n",
              "      <td>3297.0</td>\n",
              "      <td>2.244384</td>\n",
              "      <td>33.93</td>\n",
              "      <td>-116.93</td>\n",
              "      <td>0.956</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   MedInc  HouseAge  AveRooms  ...  Latitude  Longitude  MedianHouseValue\n",
              "0  3.5214      15.0  3.049945  ...     37.63    -122.43             1.442\n",
              "1  5.3275       5.0  6.490060  ...     33.69    -117.39             1.687\n",
              "2  3.1000      29.0  7.542373  ...     38.44    -122.98             1.621\n",
              "3  7.1736      12.0  6.289003  ...     33.55    -117.70             2.621\n",
              "4  2.0549      13.0  5.312457  ...     33.93    -116.93             0.956\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAJnKFlYElJo"
      },
      "source": [
        "# list_files: 파일 경로를 섞은 데이터셋 반환\n",
        "filepath_dataset = tf.data.Dataset.list_files(train_filepaths, seed=42)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxHYcHweEziu",
        "outputId": "15144047-f88f-49c7-fd7e-8b161b363909"
      },
      "source": [
        "for filepath in filepath_dataset:\n",
        "    print(filepath)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'datasets/housing/my_train_05.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_16.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_01.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_17.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_00.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_14.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_10.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_02.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_12.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_19.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_07.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_09.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_13.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_15.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_11.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_18.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_04.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_06.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_03.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_08.csv', shape=(), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpNWyL3PE6ge"
      },
      "source": [
        "# 5개 파일을 한 줄씩 번갈아 읽는다\n",
        "n_readers = 5\n",
        "dataset = filepath_dataset.interleave(\n",
        "    lambda filepath: tf.data.TextLineDataset(filepath).skip(1), # skip(1): 열 이름을 가진 첫 번째 행 무시\n",
        "    cycle_length=n_readers)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6S3O-dZ-GCuE",
        "outputId": "6521a922-d714-483f-8651-1e0484ecae35"
      },
      "source": [
        "for line in dataset.take(5):\n",
        "    print(line.numpy())"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'2.1856,41.0,3.7189873417721517,1.0658227848101265,803.0,2.0329113924050635,32.76,-117.12,1.205'\n",
            "b'4.2708,45.0,5.121387283236994,0.953757225433526,492.0,2.8439306358381504,37.48,-122.19,2.67'\n",
            "b'3.8456,35.0,5.461346633416459,0.9576059850374065,1154.0,2.8778054862842892,37.96,-122.05,1.598'\n",
            "b'3.0217,22.0,4.983870967741935,1.1008064516129032,615.0,2.4798387096774195,38.76,-120.6,1.069'\n",
            "b'4.2083,44.0,5.323204419889502,0.9171270718232044,846.0,2.3370165745856353,37.47,-122.2,2.782'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfq5NSdxJgF5"
      },
      "source": [
        "- 데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeYLuLpVGGNr"
      },
      "source": [
        "# 전처리를 위한 간단한 함수\n",
        "n_inputs = 8 # X_train.shape[-1]\n",
        "\n",
        "@tf.function\n",
        "def preprocess(line):\n",
        "    defs = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)]\n",
        "    fields = tf.io.decode_csv(line, record_defaults=defs)\n",
        "    x = tf.stack(fields[:-1])\n",
        "    y = tf.stack(fields[-1:])\n",
        "    return (x - X_mean) / X_std, y"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyh0s3CHGqON",
        "outputId": "977ff8b7-72f9-4be7-96fd-e8ece48fb9e8"
      },
      "source": [
        "# 전처리 함수 테스트\n",
        "preprocess(b'4.2083,44.0,5.3232,0.9171,846.0,2.3370,37.47,-122.2,2.782')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=\n",
              " array([ 0.16579157,  1.216324  , -0.05204565, -0.39215982, -0.5277444 ,\n",
              "        -0.2633488 ,  0.8543046 , -1.3072058 ], dtype=float32)>,\n",
              " <tf.Tensor: shape=(1,), dtype=float32, numpy=array([2.782], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yj461i1hJnkB"
      },
      "source": [
        "- 데이터 적재와 전처리 합치기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbTgIcblJVi8"
      },
      "source": [
        "# csv파일에서 캘리포니아 주택 데이터셋을 효율적으로 적재하고 전처리, 셔플링, 반복, 배치를 적용한 데이터셋을 반환하는 함수\n",
        "def csv_reader_dataset(filepaths, repeat=1, n_readers=5,\n",
        "                       n_read_threads=None, shuffle_buffer_size=10000,\n",
        "                       n_parse_threads=5, batch_size=32):\n",
        "    dataset = tf.data.Dataset.list_files(filepaths).repeat(repeat)\n",
        "    dataset = dataset.interleave(\n",
        "        lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
        "        cycle_length=n_readers, num_parallel_calls=n_read_threads)\n",
        "    dataset = dataset.shuffle(shuffle_buffer_size)\n",
        "    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    return dataset.prefetch(1)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2d_lLE-KKQ4"
      },
      "source": [
        "- 프리페치 (prefetch)\n",
        "\n",
        " 훈련 알고리즘이 한 배치로 작업을 하는 동안 이 데이터셋이 동시에 다음 배치를 준비하게 해준다. (훈련 속도가 빨라짐)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUZmPxbeJrW1",
        "outputId": "e33a5976-a91c-4797-c021-0bdb89b4cf22"
      },
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "train_set = csv_reader_dataset(train_filepaths, batch_size=3)\n",
        "for X_batch, y_batch in train_set.take(2):\n",
        "    print(\"X =\", X_batch)\n",
        "    print(\"y =\", y_batch)\n",
        "    print()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X = tf.Tensor(\n",
            "[[ 0.5804519  -0.20762321  0.05616303 -0.15191229  0.01343246  0.00604472\n",
            "   1.2525111  -1.3671792 ]\n",
            " [ 5.818099    1.8491895   1.1784915   0.28173092 -1.2496178  -0.3571987\n",
            "   0.7231292  -1.0023477 ]\n",
            " [-0.9253566   0.5834586  -0.7807257  -0.28213993 -0.36530012  0.27389365\n",
            "  -0.76194876  0.72684526]], shape=(3, 8), dtype=float32)\n",
            "y = tf.Tensor(\n",
            "[[1.752]\n",
            " [1.313]\n",
            " [1.535]], shape=(3, 1), dtype=float32)\n",
            "\n",
            "X = tf.Tensor(\n",
            "[[-0.8324941   0.6625668  -0.20741376 -0.18699841 -0.14536144  0.09635526\n",
            "   0.9807942  -0.67250353]\n",
            " [-0.62183803  0.5834586  -0.19862501 -0.3500319  -1.1437552  -0.3363751\n",
            "   1.107282   -0.8674123 ]\n",
            " [ 0.8683102   0.02970133  0.3427381  -0.29872298  0.7124906   0.28026953\n",
            "  -0.72915536  0.86178064]], shape=(3, 8), dtype=float32)\n",
            "y = tf.Tensor(\n",
            "[[0.919]\n",
            " [1.028]\n",
            " [2.182]], shape=(3, 1), dtype=float32)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVHajncMJ8IH"
      },
      "source": [
        "train_set = csv_reader_dataset(train_filepaths, repeat=None)\n",
        "valid_set = csv_reader_dataset(valid_filepaths)\n",
        "test_set = csv_reader_dataset(test_filepaths)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HKpgSfYJ_Nx"
      },
      "source": [
        "# 모델을 만들어 평가해보자\n",
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(1),\n",
        "])"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leLxTqTMKA17",
        "outputId": "9ea7c9f6-457d-4ab9-8f5f-42b85b41ba9f"
      },
      "source": [
        "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
        "\n",
        "batch_size = 32\n",
        "model.fit(train_set, steps_per_epoch=len(X_train) // batch_size, epochs=10,\n",
        "          validation_data=valid_set)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "362/362 [==============================] - 1s 3ms/step - loss: 1.4679 - val_loss: 21.5124\n",
            "Epoch 2/10\n",
            "362/362 [==============================] - 1s 2ms/step - loss: 0.8735 - val_loss: 0.6648\n",
            "Epoch 3/10\n",
            "362/362 [==============================] - 1s 3ms/step - loss: 0.6317 - val_loss: 0.6196\n",
            "Epoch 4/10\n",
            "362/362 [==============================] - 1s 3ms/step - loss: 0.5933 - val_loss: 0.5669\n",
            "Epoch 5/10\n",
            "362/362 [==============================] - 1s 2ms/step - loss: 0.5629 - val_loss: 0.5402\n",
            "Epoch 6/10\n",
            "362/362 [==============================] - 1s 3ms/step - loss: 0.5693 - val_loss: 0.5209\n",
            "Epoch 7/10\n",
            "362/362 [==============================] - 1s 2ms/step - loss: 0.5231 - val_loss: 0.6130\n",
            "Epoch 8/10\n",
            "362/362 [==============================] - 1s 2ms/step - loss: 0.5074 - val_loss: 0.4818\n",
            "Epoch 9/10\n",
            "362/362 [==============================] - 1s 3ms/step - loss: 0.4963 - val_loss: 0.4904\n",
            "Epoch 10/10\n",
            "362/362 [==============================] - 1s 2ms/step - loss: 0.5023 - val_loss: 0.4585\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa5a828aa50>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywhG48QzKGU1",
        "outputId": "634703b8-66d3-484a-abd3-934d0efc0a23"
      },
      "source": [
        "model.evaluate(test_set, steps=len(X_test) // batch_size)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "161/161 [==============================] - 0s 2ms/step - loss: 0.4788\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4787752032279968"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afmVFLw3KI2x",
        "outputId": "cbfdf8ab-d1c3-4280-d6de-d0e5b40bba19"
      },
      "source": [
        "new_set = test_set.map(lambda X, y: X)\n",
        "X_new = X_test\n",
        "model.predict(new_set, steps=len(X_new) // batch_size)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.3576405],\n",
              "       [2.255291 ],\n",
              "       [1.4437605],\n",
              "       ...,\n",
              "       [0.5654392],\n",
              "       [3.9442453],\n",
              "       [1.0232248]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSsHgmHrMq3C"
      },
      "source": [
        "### 13.2 TFRecord 포맷"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCkxuV_2M88L"
      },
      "source": [
        "- TFRecord: 대용량 데이터를 저장하고 효율적으로 읽기 위해 텐서플로가 선호하는 포맷\n",
        "\n",
        " 크기가 다른 연속된 이진 레코드를 저장하는 단순한 이진 포맷이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovUNPXSUMMl5"
      },
      "source": [
        "with tf.io.TFRecordWriter('my_data.tfrecord') as f:\n",
        "    f.write(b'This is the first record')\n",
        "    f.write(b'And this is the second record')"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uxoLthbM4nj",
        "outputId": "d7f8c587-2217-4c30-ea40-04a6a9e45e01"
      },
      "source": [
        "# tf.data.TFRecordDataset으로 하나 이상의 TFRecord를 읽을 수 있다\n",
        "filepaths = [\"my_data.tfrecord\"]\n",
        "dataset = tf.data.TFRecordDataset(filepaths)\n",
        "for item in dataset:\n",
        "    print(item)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'This is the first record', shape=(), dtype=string)\n",
            "tf.Tensor(b'And this is the second record', shape=(), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNOYwO3GM7QL"
      },
      "source": [
        "# TFRecord 파일 압축\n",
        "options = tf.io.TFRecordOptions(compression_type=\"GZIP\")\n",
        "with tf.io.TFRecordWriter(\"my_compressed.tfrecord\", options) as f:  # options매개변수를 사용하여 압축\n",
        "    f.write(b\"This is the first record\")\n",
        "    f.write(b\"And this is the second record\")"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IeMd1PVOEry"
      },
      "source": [
        "dataset = tf.data.TFRecordDataset(['my_compressed.tfrecord'],\n",
        "                                  compression_type='GZIP')  # 압축 형식을 지정해야 압축된 파일을 읽을 수 있다"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mb78LmAOMzC",
        "outputId": "d9bfb6f5-26ac-4181-b7b1-fe217a2f5d54"
      },
      "source": [
        "for item in dataset:\n",
        "    print(item)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'This is the first record', shape=(), dtype=string)\n",
            "tf.Tensor(b'And this is the second record', shape=(), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEg2Y_y6OOwF",
        "outputId": "f22adfd7-2b83-43a6-accf-60d949eedc85"
      },
      "source": [
        "# 프로토콜 버퍼 정의\n",
        "%%writefile person.proto\n",
        "syntax = \"proto3\";\n",
        "message Person {\n",
        "  string name = 1;\n",
        "  int32 id = 2;\n",
        "  repeated string email = 3;\n",
        "}"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing person.proto\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-44KfdVQr48",
        "outputId": "a89f6da7-6401-4af6-82f4-0f8a21cb9d50"
      },
      "source": [
        "!protoc person.proto --python_out=. --descriptor_set_out=person.desc --include_imports\n",
        "\n",
        "!ls person*"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "person.desc  person_pb2.py  person.proto\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_K27ktDQEFH",
        "outputId": "b42f18ff-7332-4524-df86-eb9c67d0dde6"
      },
      "source": [
        "# 생성된 클래스 임포트\n",
        "from person_pb2 import Person\n",
        "\n",
        "person = Person(name=\"Al\", id=123, email=[\"a@b.com\"])  # Person 객체 생성\n",
        "print(person)  # Person 출력"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name: \"Al\"\n",
            "id: 123\n",
            "email: \"a@b.com\"\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rjLiXKTHQnUs",
        "outputId": "bc566e4c-6e3c-4fa5-8578-a80f42373e18"
      },
      "source": [
        "person.name  # 필드 읽기"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Al'"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dv5DggekQySC"
      },
      "source": [
        "person.name = \"Alice\"  # 필드 수정"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZcxT_DIXQz-o",
        "outputId": "410e793a-171c-42f6-8748-b079b503018a"
      },
      "source": [
        "person.email[0]  # 배열처럼 사용할 수 있는 반복 필드"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'a@b.com'"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2N6tEn3-Q1DX"
      },
      "source": [
        "person.email.append(\"c@d.com\")  # 이메일 추가"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsrcEcWlQ6YS",
        "outputId": "9482709b-9f29-47eb-aab1-5cbc3253324c"
      },
      "source": [
        "s = person.SerializeToString()  # 바이트 문자열로 직렬화\n",
        "s"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'\\n\\x05Alice\\x10{\\x1a\\x07a@b.com\\x1a\\x07c@d.com'"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8o1NnPqQ-xV",
        "outputId": "9ca9ba5b-1eac-4f4d-f08e-3e34bcc4bc53"
      },
      "source": [
        "person2 = Person()  # 새로운 Person 생성\n",
        "person2.ParseFromString(s)  # 바이트 문자열 파싱 (27 바이트)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-j5FbX7eRBLs",
        "outputId": "3dc951c8-f405-482f-d62b-1f083d8f4d5d"
      },
      "source": [
        "person == person2  # 동일"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTyYS0qKSIcV"
      },
      "source": [
        "from tensorflow.train import BytesList, FloatList, Int64List\n",
        "from tensorflow.train import Feature, Features, Example\n",
        "\n",
        "person_example = Example(\n",
        "    features=Features(\n",
        "        feature={\n",
        "            \"name\": Feature(bytes_list=BytesList(value=[b\"Alice\"])),\n",
        "            \"id\": Feature(int64_list=Int64List(value=[123])),\n",
        "            \"emails\": Feature(bytes_list=BytesList(value=[b\"a@b.com\", b\"c@d.com\"]))\n",
        "        }))\n",
        "\n",
        "with tf.io.TFRecordWriter(\"my_contacts.tfrecord\") as f:\n",
        "    f.write(person_example.SerializeToString())"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6is2w_mfVats"
      },
      "source": [
        "### 13.3 입력 특성 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_t_O7UBGSsQr"
      },
      "source": [
        "# 표준화를 수행하는 층 구현\n",
        "class Standardization(keras.layers.Layer):\n",
        "    def adapt(self, data_sample):\n",
        "        self.means_ = np.mean(data_sample, axis=0, keepdims=True)\n",
        "        self.stds_ = np.std(data_sample, axis=0, keepdims=True)\n",
        "    def call(self, inputs):\n",
        "        return (inputs - self.means_) / (self.stds_ + keras.backend.epsilon())"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODztB-4vWUFf"
      },
      "source": [
        "vocab = ['<1H OCEAN', 'INLAND', 'NEAR OCEAN', 'NEAR BAY', 'ISLAND'] # 어휘 사전 정의 (가능한 모든 범주의 리스트)\n",
        "indices = tf.range(len(vocab), dtype=tf.int64)\n",
        "table_init = tf.lookup.KeyValueTensorInitializer(vocab, indices)\n",
        "num_oov_buckets = 2\n",
        "table = tf.lookup.StaticVocabularyTable(table_init, num_oov_buckets)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHQDAJT3ZJEL",
        "outputId": "e5128f1f-eb1a-4449-aec1-0e7c7e18a24c"
      },
      "source": [
        "categories = tf.constant(['NEAR BAY', 'DESERT', 'INLAND', 'ISLAND'])\n",
        "cat_indices = table.lookup(categories)\n",
        "cat_indices"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4,), dtype=int64, numpy=array([3, 5, 1, 4])>"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dc-gwCg9ZriH",
        "outputId": "09338277-452c-475c-956a-d2149ea49c46"
      },
      "source": [
        "cat_one_hot = tf.one_hot(cat_indices, depth=len(vocab) + num_oov_buckets)\n",
        "cat_one_hot"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 7), dtype=float32, numpy=\n",
              "array([[0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQsxGrk9ZzYg"
      },
      "source": [
        "# 임베딩으로 범주형 특성 인코딩하기\n",
        "embedding_dim = 2\n",
        "embed_init = tf.random.uniform([len(vocab) + num_oov_buckets, embedding_dim])\n",
        "embedding_matrix = tf.Variable(embed_init)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAL0o0nCaWX2",
        "outputId": "2c6d7fd4-5a76-4392-838e-ea9354763bd8"
      },
      "source": [
        "embedding_matrix"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(7, 2) dtype=float32, numpy=\n",
              "array([[0.7413678 , 0.62854624],\n",
              "       [0.01738465, 0.3431449 ],\n",
              "       [0.51063764, 0.3777541 ],\n",
              "       [0.07321596, 0.02137029],\n",
              "       [0.2871771 , 0.4710616 ],\n",
              "       [0.6936141 , 0.07321334],\n",
              "       [0.93251204, 0.20843053]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tgow7Hrad-8",
        "outputId": "b41b3916-5587-4180-a41b-8024b3d937f4"
      },
      "source": [
        "categories = tf.constant(['NEAR BAY', 'DESERT', 'INLAND', 'ISLAND'])\n",
        "cat_indices = table.lookup(categories)\n",
        "cat_indices"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4,), dtype=int64, numpy=array([3, 5, 1, 4])>"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtL6cyDFarnx",
        "outputId": "d23c77c6-e83c-4fb9-a182-d7fdad8d58c1"
      },
      "source": [
        "tf.nn.embedding_lookup(embedding_matrix, cat_indices)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
              "array([[0.07321596, 0.02137029],\n",
              "       [0.6936141 , 0.07321334],\n",
              "       [0.01738465, 0.3431449 ],\n",
              "       [0.2871771 , 0.4710616 ]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    }
  ]
}
