{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter03",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXBpAYlIDlol"
      },
      "source": [
        "# Chapter 03 신경망\n",
        "\n",
        "퍼셉트론으로 복잡한 함수도 표현할 수 있다.\n",
        "\n",
        "하지만 가중치를 설정하는 작업은 사람이 수동으로 해야 한다.\n",
        "\n",
        "--> **신경망**으로 가중치 매개변수의 적절한 값을 데이터로부터 자동으로 학습할 수 있다!!\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2o2tTeSFZAn"
      },
      "source": [
        "신경망은\n",
        "\n",
        "1. **입력층** : (0층)\n",
        "2. **은닉층** : 사람 눈에 보이지 않는다 (1층)\n",
        "3. **출력층** : (2층)\n",
        "\n",
        "으로 나뉘어져 있다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldE9RD5TNmPU"
      },
      "source": [
        "### 3.2 활성화 함수\n",
        "임계값을 경계로 출력이 바뀜 --> 계단함수 (step function)\n",
        "\n",
        "퍼셉트론에서는 활성화 함수로 계단함수를 이용한다.\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BD8dzgjHOEzO"
      },
      "source": [
        "**시그모이드 함수**\n",
        "\n",
        "신경망에서 자주 이용하는 활성화 함수\n",
        "\n",
        "h(x) = 1 / (1 + exp(-x))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7i-x-UHrDicG"
      },
      "source": [
        "# 계단 함수 구현하기\n",
        "def step_function(x):  # 인수로 실수만 받음\n",
        "    if x > 0:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "import numpy as np\n",
        "# 넘파이 배열도 인수(x)로 지원하기 위한 구현\n",
        "def step_funtion(x):\n",
        "    y = x > 0\n",
        "    return y.astype(np.int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8H-V_yAO-Mg"
      },
      "source": [
        "import numpy as np\n",
        "x = np.array([-1.0, 1.0, 2.0])\n",
        "print(x)\n",
        "\n",
        "y = x > 0          # 0보다 큰 x는 True, 아니면 False로 하는 배열 y생성\n",
        "y.astype(np.int)   # 자료형을 정수형으로 바꿈"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peWS-TbXRA5d"
      },
      "source": [
        "# step function 그리기\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def step_function(x):\n",
        "    return np.array(x > 0, dtype=np.int)\n",
        "\n",
        "x = np.arange(-5.0, 5.0, 0.1)  # -5.0 ~ 5.0 까지 0.1간격으로 넘파이 배열 생성\n",
        "y = step_function(x)\n",
        "plt.plot(x, y)\n",
        "plt.ylim(-0.1, 1.1)  # y축의 범위 지정\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5eN0btyRwMV"
      },
      "source": [
        "# 시그모이드 함수 구현하기\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "x = np.array([-0.1, 1.0, 2.0])\n",
        "sigmoid(x)  # x가 넘파이 배열이어도 브로드캐스트 덕분에 제대로 처리한다!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1da46K-2SQg-"
      },
      "source": [
        "# 넘파이 브로드캐스트 복습\n",
        "t = np.array([1.0, 2.0, 3.0])\n",
        "print(1.0 + t)\n",
        "print(1.0 / t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XamxFgUBVjrV"
      },
      "source": [
        "# 시그모이드 함수 그리기\n",
        "x = np.arange(-5.0, 5.0, 0.1)\n",
        "y = sigmoid(x)\n",
        "plt.plot(x, y)\n",
        "plt.ylim(-0.1, 1.1)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7Bht6o-WY7a"
      },
      "source": [
        "- 시그모이드 함수 : 매끄럽다 (연속적이다)\n",
        "\n",
        "- 계단 함수 : 불연속적이다\n",
        "\n",
        "둘 다 입력이 작으면 0, 커지면 1에 가까워진다.\n",
        "\n",
        "---\n",
        "\n",
        "시그모이드, 계단 함수 둘 다 비선형 함수이다.\n",
        "\n",
        "선형 함수를 이용해서는 여러 층으로 구성하는 이점을 살릴 수가 없다. --> 비선형 함수를 이용해야 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W26EKWbUW8IS"
      },
      "source": [
        "**ReLU** 함수 :\n",
        "\n",
        "입력이 0을 넘으면 그 입력 그대로 출력, 0 이하이면 0을 출력하는 함수\n",
        "\n",
        "```\n",
        "h(x) = x (x > 0)\n",
        "     = 0 (x <= 0)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzFSvhFGWwWe"
      },
      "source": [
        "# ReLU 함수 구현\n",
        "def relu(x):\n",
        "    return np.maximum(0,x)  # np.maximum() : 두 입력 중 큰 값 반환"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztOQAHZWYDsR"
      },
      "source": [
        "# 넘파이 다차원 배열\n",
        "\n",
        "# 1차원\n",
        "import numpy as np\n",
        "A = np.array([1,2,3,4])\n",
        "print(A)\n",
        "print(np.ndim(A))   # 배열의 차원 수\n",
        "print(A.shape)      # 배열의 형상\n",
        "print(A.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6AfUIIYYUPU"
      },
      "source": [
        "# 2차원\n",
        "B = np.array([[1,2], [3,4], [5,6]])   # 3x2 배열\n",
        "print(B)\n",
        "print(np.ndim(B))\n",
        "print(B.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_u_aWh3Zp2q"
      },
      "source": [
        "# 행렬의 곱\n",
        "A = np.array([[1,2], [3,4]])   # 행렬은 대개 대문자로 표시\n",
        "print(A.shape)\n",
        "B = np.array([[5,6], [7,8]])\n",
        "print(B.shape)\n",
        "print(np.dot(A,B))  # np.dot(): 행렬 곱"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O7zXpgIaEp5"
      },
      "source": [
        "A = np.array([[1,2,3], [4,5,6]])\n",
        "print(A.shape)\n",
        "B = np.array([[1,2], [3,4], [5,6]])\n",
        "print(B.shape)\n",
        "print(np.dot(A,B))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9HFB5mNag4M"
      },
      "source": [
        "C = np.array([[1,2], [3,4]])\n",
        "print(A.shape, C.shape)\n",
        "#np.dot(A,C)     # 행렬의 형상에 주의!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0nVE7v8ahJc"
      },
      "source": [
        "A = np.array([[1,2], [3,4], [5,6]])\n",
        "B = np.array([7,8])\n",
        "np.dot(A,B)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efOqUhdVa8NK"
      },
      "source": [
        "# 신경망에서의 행렬 곱\n",
        "\n",
        "X = np.array([1,2])\n",
        "print(X.shape)\n",
        "\n",
        "W = np.array([[1,3,5], [2,4,6]])\n",
        "print(W)\n",
        "print(W.shape)\n",
        "\n",
        "Y = np.dot(X,W)\n",
        "print(Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WFF_V_NYjxF"
      },
      "source": [
        "### 3.4, 3층 신경망 구현하기\n",
        "\n",
        "입력층 ( 0층 ), 은닉층 ( 1층, 2층 ), 출력층 ( 3층 ) 으로 구성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "De7LrstxV3oR"
      },
      "source": [
        "X = np.array([1.0, 0.5])\n",
        "W1 = np.array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]])\n",
        "B1 = np.array([0.1, 0.2, 0.3])\n",
        "\n",
        "print(W1.shape)\n",
        "print(X.shape)\n",
        "print(B1.shape)\n",
        "\n",
        "A1 = np.dot(X, W1) + B1\n",
        "print(A1)\n",
        "\n",
        "# 활성화 함수 처리\n",
        "Z1 = sigmoid(A1)    # 앞에서 이미 정의했음\n",
        "print(Z1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynxbYrXLceAN"
      },
      "source": [
        "# 1충에서 2층으로 가는 과정\n",
        "W2 = np.array([[0.1, 0.4], [0.2, 0.5], [0.3, 0.6]])\n",
        "B2 = np.array([0.1, 0.2])\n",
        "\n",
        "print(Z1.shape)\n",
        "print(W2.shape)\n",
        "print(B2.shape)\n",
        "\n",
        "A2 = np.dot(Z1, W2) + B2\n",
        "print(A2)\n",
        "Z2 = sigmoid(A2)\n",
        "print(Z2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Un0RY4wio6it"
      },
      "source": [
        "def identity_function(x):   # 출력층의 활성화 함수 (항등 함수)\n",
        "    return x\n",
        "\n",
        "W3 = np.array([[0.1, 0.3], [0.2, 0.4]])\n",
        "B3 = np.array([0.1, 0.2])\n",
        "\n",
        "A3 = np.dot(Z2, W3) + B3\n",
        "print(A3)\n",
        "Y = identity_function(A3)   # Y = A3 과 같음\n",
        "print(Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqcInEE7pg9f"
      },
      "source": [
        "def init_network():     # 가중치, 편향을 초기화하는 함수\n",
        "    network = {}\n",
        "    network['W1'] = np.array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]])\n",
        "    network['b1'] = np.array([0.1, 0.2, 0.3])\n",
        "    network['W2'] = np.array([[0.1, 0.4], [0.2, 0.5], [0.3, 0.6]])\n",
        "    network['b2'] = np.array([0.1, 0.2])\n",
        "    network['W3'] = np.array([[0.1, 0.3], [0.2, 0.4]])\n",
        "    network['b3'] = np.array([0.1, 0.2])\n",
        "\n",
        "    return network\n",
        "\n",
        "def forward(network, x):   # 입력 신호를 출력으로 변환하는 함수\n",
        "    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
        "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
        "\n",
        "    a1 = np.dot(x, W1) + b1\n",
        "    z1 = sigmoid(a1)\n",
        "    a2 = np.dot(z1, W2) + b2\n",
        "    z2 = sigmoid(a2)\n",
        "    a3 = np.dot(z2, W3) + b3\n",
        "    y = identity_function(a3)\n",
        "\n",
        "    return y\n",
        "\n",
        "\n",
        "network = init_network()\n",
        "x = np.array([1.0, 0.5])\n",
        "y = forward(network, x)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wd2Q9z4btrx8"
      },
      "source": [
        "### 3.5 출력층 설계하기\n",
        "\n",
        "신경망은 분류와 회귀에 모두 이용 가능 ( 출력층에서 활성화 함수가 다름 )\n",
        "\n",
        "- 회귀 : 항등 함수\n",
        "\n",
        "- 분류 : 소프트맥스 함수"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdE71cC6ulI8"
      },
      "source": [
        "소프트맥스 함수 : y(k) = exp(a(k)) / sum(exp(a(i)))\n",
        "\n",
        "--> k번째 exp 에서 모든 exp 의 합을 나눈다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbPkDfBKtmD7"
      },
      "source": [
        "# 소프트맥스 함수 구현하기\n",
        "a = np.array([0.3, 2.9, 4.0])\n",
        "exp_a = np.exp(a)\n",
        "print(exp_a)\n",
        "\n",
        "sum_exp_a = np.sum(exp_a)\n",
        "print(sum_exp_a)\n",
        "\n",
        "y = exp_a / sum_exp_a\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRU5KRsmudPu"
      },
      "source": [
        "# 함수로 구현\n",
        "def softmax(a):\n",
        "    exp_a = np.exp(a)\n",
        "    sum_exp_a = np.sum(exp_a)\n",
        "    y = exp_a / sum_exp_a\n",
        "\n",
        "    return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTng0Js_vTLh"
      },
      "source": [
        "# 소프트맥스 함수 구현 시 주의점: 수가 커지면 오버플로가 발생할 수 있다\n",
        "\n",
        "a = np.array([1010, 1000, 990])\n",
        "np.exp(a) / np.sum(np.exp(a))   # 오버플로 발생\n",
        "\n",
        "c = np.max(a)\n",
        "np.exp(a - c) / np.sum(np.exp(a - c))  # 입력값의 최대값을 빼준다 (계산값은 똑같다!)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvRPmXWDwy9W"
      },
      "source": [
        "# 오버플로 문제점을 보안한 소프트맥스 함수\n",
        "def softmax(a):\n",
        "    c = np.max(a)\n",
        "    exp_a = np.exp(a - c)\n",
        "    sum_exp_a = np.sum(exp_a)\n",
        "    y = exp_a / sum_exp_a\n",
        "\n",
        "    return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxx00ZrZxBS5"
      },
      "source": [
        "a = np.array([0.3, 2.9, 4.0])\n",
        "y = softmax(a)\n",
        "print(y)\n",
        "print(np.sum(y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fh9p7LPPLgba"
      },
      "source": [
        "- 소프트맥스 함수 출력의 총합은 1 이다 --> 출력을 '확률' 로 해석할 수 있다.\n",
        "\n",
        "- 출력층의 뉴런 수 : 분류에서는 분류하고 싶은 클래스 수로 설정한다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TD23VGT1NwX1"
      },
      "source": [
        "### 3.6 손글씨 숫자 인식\n",
        "\n",
        "MNIST 데이터셋 : 손글씨 숫자 이미지 집합\n",
        "\n",
        "각 이미지 데이터는 28 x 28 크기의 이미지이며, 각 픽셀은 0~255까지의 값을 취한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_QFQX8CxIsa"
      },
      "source": [
        "import sys, os\n",
        "os.chdir(\"/content/drive/MyDrive/밑바닥부터시작하는딥러닝\")\n",
        "sys.path.append(os.chdir)\n",
        "from dataset.mnist import load_mnist\n",
        "\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=True, normalize=False)\n",
        "#                                      flatten 1차원배열로 만들지, normalize : 픽셀값을 정규화할지\n",
        "print(x_train.shape)  # 훈련 이미지\n",
        "print(t_train.shape)  # 훈련 레이블\n",
        "print(x_test.shape)   # 시험 이미지\n",
        "print(t_test.shape)   # 시험 레이블"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tldJQuSTSx4k"
      },
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "def img_show(img):\n",
        "    pil_img = Image.fromarray(np.uint8(img))\n",
        "    pil_img.show()\n",
        "\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=True, normalize=False)\n",
        "\n",
        "img = x_train[0]\n",
        "label = t_train[0]\n",
        "print(label)  # 5\n",
        "\n",
        "print(img.shape)  # (784,)\n",
        "img = img.reshape(28, 28)  # 형상을 원래 이미지의 크기로 변형\n",
        "print(img.shape)  # (28, 28)\n",
        "\n",
        "img_show(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_MXSSCabEs4"
      },
      "source": [
        "MNIST 데이터셋으로 신경망 구현하기 :\n",
        "\n",
        "입력층 뉴런을 784개 ( 28x28 ), 출력층 뉴런을 10개로 ( 레이블 수 ),\n",
        "\n",
        "은닉층은 두 개로, 첫번째는 50개, 두번째는 100개로 임의로 지정."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_XAKOESSy5f"
      },
      "source": [
        "import sys, os\n",
        "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
        "import numpy as np\n",
        "import pickle   # 'pickle'은 프로그램 실행 중에 특정 객체를 파일로 저장하는 기능\n",
        "from common.functions import sigmoid, softmax\n",
        "\n",
        "def get_data():\n",
        "    (x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, flatten=True, one_hot_label=False)\n",
        "    return x_test, t_test\n",
        "\n",
        "def init_network():\n",
        "    with open(\"/content/drive/MyDrive/밑바닥부터시작하는딥러닝/deep-learning-from-scratch-master/ch03/sample_weight.pkl\", 'rb') as f:\n",
        "        network = pickle.load(f)\n",
        "    return network\n",
        "\n",
        "def predict(network, x):    # 신경망 추론 함수\n",
        "    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
        "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
        "\n",
        "    a1 = np.dot(x, W1) + b1\n",
        "    z1 = sigmoid(a1)\n",
        "    a2 = np.dot(z1, W2) + b2\n",
        "    z2 = sigmoid(a2)\n",
        "    a3 = np.dot(z2, W3) + b3\n",
        "    y = softmax(a3)\n",
        "    return y\n",
        "\n",
        "\n",
        "x, t = get_data()   # 테스트세트의 데이터, 타깃\n",
        "network = init_network()\n",
        "accuracy_cnt = 0\n",
        "for i in range(len(x)):\n",
        "    y = predict(network, x[i])\n",
        "    p= np.argmax(y)     # 확률이 가장 높은 원소의 인덱스를 얻는다\n",
        "    if p == t[i]:\n",
        "        accuracy_cnt += 1   # 예측값과 레이블 값이 같으면 accuracy 1증가\n",
        "\n",
        "\n",
        "print(\"Accuracy:\" + str(float(accuracy_cnt) / len(x)))  # 올바르게 분류한 확률"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRoqQEMibpEm"
      },
      "source": [
        "x, _ = get_data()\n",
        "network = init_network()\n",
        "W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
        "\n",
        "print(x.shape)\n",
        "print(x[0].shape)\n",
        "print(W1.shape)\n",
        "print(W2.shape)\n",
        "print(W3.shape)\n",
        "\n",
        "# 다차원 배열의 대응하는 차원의 원소 수가 일치한다"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahihOFJLgo1G"
      },
      "source": [
        "x, t = get_data()\n",
        "network = init_network()\n",
        "\n",
        "# 하나로 묶은 입력 데이터를 '배치' 라고 한다\n",
        "# 배치 처리를 하면 큰 배열을 효율적으로 처리할 수 있고, 버스에 주는 부하를 줄여준다\n",
        "batch_size = 100    # 배치 크기\n",
        "accuracy_cnt = 0\n",
        "\n",
        "for i in range(0, len(x), batch_size):\n",
        "    x_batch = x[i:i+batch_size]\n",
        "    y_batch = predict(network, x_batch)\n",
        "    p = np.argmax(y_batch, axis=1)\n",
        "    accuracy_cnt += np.sum(p == t[i:i+batch_size])\n",
        "\n",
        "\n",
        "print(\"Accuracy:\" + str(float(accuracy_cnt) / len(x)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ywmgKCHixDT"
      },
      "source": [
        "x = np.array([[0.1, 0.8, 0.1],\n",
        "              [0.3, 0.1, 0.6],\n",
        "              [0.2, 0.5, 0.3],\n",
        "              [0.8, 0.1, 0.1]])\n",
        "y = np.argmax(x, axis=1)    # axis=1 : 수평, axis=0 : 수직\n",
        "print(y)\n",
        "y = np.argmax(x, axis=0)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNpBtiVojPxk"
      },
      "source": [
        "y = np.array([1, 2, 1, 0])\n",
        "t = np.array([1, 2, 0, 0])\n",
        "print(y == t)   # bool배열을 만든다\n",
        "print()\n",
        "np.sum(y == t)  # True인 원소의 개수를 세어준다"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}